{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echo State Network against Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from qbraid_algorithms import EchoStateNetwork, EchoStateReservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EchoStateReservoir:  # pylint: disable=too-many-instance-attributes\n",
    "    \"\"\"Dataclass for a reservoir component of an Echo State Network.\"\"\"\n",
    "\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    sparsity: float = 0.9\n",
    "    spectral_radius: float = 0.99\n",
    "    a: float = 0.6\n",
    "    leak: float = 1.0\n",
    "    max_retries: int = 3\n",
    "    w_in: torch.Tensor = field(init=False)\n",
    "    w: torch.Tensor = field(init=False)\n",
    "    x: torch.Tensor = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.w_in = self._generate_w_in()\n",
    "        self.w = self._generate_w(max_retries=self.max_retries)\n",
    "        self.x = torch.zeros(self.hidden_size, 1)\n",
    "\n",
    "    def _generate_w_in(self, mean: float = 0.0) -> torch.Tensor:\n",
    "        \"\"\"Generates and returns a random input weight matrix, w_in.\"\"\"\n",
    "        return torch.randn(self.hidden_size, self.input_size + 1).normal_(mean=mean, std=self.a)\n",
    "\n",
    "    def _generate_w(self, mean: float = 0.0, max_retries: int = 3) -> torch.Tensor:\n",
    "        \"\"\"Generates a sparse internal weight matrix, w, with retries if necessary.\"\"\"\n",
    "        for attempt in range(max_retries + 1):\n",
    "            w = torch.randn(self.hidden_size, self.hidden_size).normal_(\n",
    "                mean=mean, std=self.spectral_radius\n",
    "            )\n",
    "            w = torch.where(torch.rand_like(w) > self.sparsity, w, torch.zeros_like(w))\n",
    "            eigenvalues = torch.linalg.eigvals(w)  # pylint: disable=not-callable\n",
    "            max_abs_eigenvalue = torch.max(torch.abs(eigenvalues)).item()\n",
    "            if max_abs_eigenvalue != 0:\n",
    "                w *= self.spectral_radius / max_abs_eigenvalue\n",
    "                return w\n",
    "            if attempt == max_retries:\n",
    "                raise ReservoirGenerationError(\n",
    "                    f\"Failed to generate a valid weight matrix after {max_retries} retries; \"\n",
    "                    \"max eigenvalue was zero.\"\n",
    "                )\n",
    "        return w\n",
    "\n",
    "    def evolve(self, u: torch.Tensor) -> None:\n",
    "        \"\"\"\n",
    "        Updates and returns the state representation x for a given input u.\n",
    "\n",
    "        Args:\n",
    "            u: Input vector.\n",
    "\n",
    "        \"\"\"\n",
    "        temp_state = torch.tanh(\n",
    "            torch.mm(self.w_in, torch.cat((torch.tensor([[1.0]]), u), 0)) + torch.mm(self.w, self.x)\n",
    "        )\n",
    "        new_state = (1 - self.leak) * self.x + self.leak * temp_state\n",
    "        self.x = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoStateNetwork(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    An Echo State Network module that combines a Reservoir with a fully connected output layer.\n",
    "\n",
    "    Attributes:\n",
    "        reservoir (Reservoir): The reservoir component of the ESN.\n",
    "        fc (torch.nn.Linear): Linear layer to map reservoir states to output dimensions.\n",
    "        softmax (torch.nn.Softmax): Softmax activation function for generating output probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reservoir: EchoStateReservoir, output_size: int):\n",
    "        \"\"\"\n",
    "        Initializes the Echo State Network with a reservoir and a linear output layer.\n",
    "\n",
    "        Args:\n",
    "            reservoir (EchoStateReservoir): Reservoir component of the ESN.\n",
    "            output_size (int): Size of each output sample.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.reservoir = reservoir\n",
    "        self.fc = torch.nn.Linear(in_features=reservoir.hidden_size, out_features=output_size)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_data: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Processes the input through the network and returns the output probabilities.\n",
    "\n",
    "        Args:\n",
    "            input_data: A tensor of input data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor containing the softmax probabilities of the outputs.\n",
    "        \"\"\"\n",
    "        u = input_data.flatten()  # Flatten data into a single vector\n",
    "        u = input_data.unsqueeze(dim=0).t()  # Transpose to desired input shape for the reservoir\n",
    "\n",
    "        self.reservoir.evolve(u)  # Pass through reservoir\n",
    "\n",
    "        h = self.fc(self.reservoir.x.t())  # Pass transposed output x through the linear layer\n",
    "        # h = self.softmax(h)  # Apply softmax to get probabilities\n",
    "        return h # Softmax unnecessary for 1-d output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format Time Series data to work with the ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        seq_x, seq_y = data[i:i+n_steps], data[i+n_steps]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32).view(-1,1, 1)\n",
    "\n",
    "n_steps = 10\n",
    "\n",
    "t = np.linspace(0, 2 * np.pi * 10, 1000)\n",
    "data = np.sin(t)\n",
    "X, y = create_sequences(data, n_steps)\n",
    "trainset = TensorDataset(X, y)\n",
    "trainloader = DataLoader(trainset, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize ESN, optimizer, and loss criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10\n",
    "output_size = 1\n",
    "hyperparams = {\n",
    "    \"hidden_size\": 2500,\n",
    "    \"sparsity\": 0.9,\n",
    "    \"spectral_radius\": 0.99,\n",
    "    \"a\": 0.6,\n",
    "    \"leak\": 1.0,\n",
    "}\n",
    "\n",
    "reservoir = EchoStateReservoir(input_size, **hyperparams)\n",
    "esn = EchoStateNetwork(reservoir, output_size).float()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(esn.parameters(), lr=0.00001)\n",
    "len_data = len(trainset)\n",
    "nsamples = 1000\n",
    "nepochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "start = time.time()\n",
    "for epoch in range(nepochs):\n",
    "    total_loss = 0.0\n",
    "    for i, dat in enumerate(trainset, 0):\n",
    "        seq = dat[0]\n",
    "        target = dat[1] \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = esn(seq)[0]  \n",
    "        loss = criterion(output, target) \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / nsamples\n",
    "    loss_values.append(average_loss)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {average_loss}\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"Training complete\")\n",
    "print(\"num samples = \" + str(nsamples))\n",
    "print(\"num epochs = \" + str(nepochs))\n",
    "print(\"total time = \" + str(end - start) + \" sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.plot(range(1, nepochs + 1), loss_values, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot against desired data, giving R^2 as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    t_test = np.linspace(2 * np.pi * 10, 2 * np.pi * 12, 400)  # continuing from where training data stopped\n",
    "    data_test = np.sin(t_test)\n",
    "    X_test, y_test = create_sequences(data_test, n_steps)\n",
    "    testset = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(testset, shuffle=True)\n",
    "    esn.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader.dataset:\n",
    "            output = esn(inputs)[0]\n",
    "            predictions.append(output)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predictions = test()\n",
    "t_test = np.linspace(2 * np.pi * 10, 2 * np.pi * 12, 400)\n",
    "plt.plot(torch.cat(predictions).numpy(), label=\"Predictions\")\n",
    "plt.plot([np.sin(y) for y in t_test], label=\"True values\")\n",
    "plt.legend()\n",
    "\n",
    "y_true = np.sin(t_test)\n",
    "y_pred = torch.cat(predictions).numpy().flatten()\n",
    "y_true_mean = np.mean(y_true)\n",
    "ss_tot = np.sum((y_true - y_true_mean) ** 2)\n",
    "ss_res = np.sum((y_true[:390] - y_pred) ** 2)\n",
    "r2 = 1 - ss_res / ss_tot\n",
    "print(\"R^2: \", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
